---
title: "Homework 2"
author: "John French"
format:
  html:
    toc: true
    toc-location: left
    self-contained: true
jupyter: python3
---

## Task 1

We are going to return to the table of the top 100 wrestlers: https://www.cagematch.net/?id=2&view=statistics. Specifically, you are going to get the ratings/comments tables for each wrestler.
```{python}
from bs4 import BeautifulSoup
import requests
import pandas as pd
import re

h2_t1_url = 'https://www.cagematch.net/?id=2&view=statistics'
h2_t1_response = requests.get(h2_t1_url)
h2_wrestler_soup = BeautifulSoup(h2_t1_response.text, 'html.parser')

h2_wrestler_table = h2_wrestler_soup.find('table', class_="TBase TableBorderColor")

h2_wrestler_rows = h2_wrestler_table.select('tr') # this has all of our information we need for finding the player and their attached URL

player_urls = []

for row in h2_wrestler_rows:
    player_url = row.find('a')
    if player_url:  # Ensure it's not None
        player_urls.append(player_url['href'])  # Extract only the href attribute

player_urls = player_urls[1:] # remove the first row as it is the header

# Create full URLs with original URL
full_player_urls = [h2_t1_url + url for url in player_urls]

cleaned_urls = []

for url in full_player_urls:
  cleaned_urls.append(re.sub(r"(nr=[0-9]+)(.*)",r"\1&page=99", url))

# Now we have the URLs for each player, we can loop through and get the ratings/comments tables

all_comments = []

for player in cleaned_urls:
  h2_t1_player_resp = requests.get(player)
  h2_t1_player_soup = BeautifulSoup(h2_t1_player_resp.text, 'html.parser')
  comments_box = (h2_t1_player_soup.select(".LayoutContent .Comment .CommentContents"))
  all_comments.append(comments_box)

h2_t1_comments_whole = []

for box_comment in all_comments:
  for comment in box_comment:
    h2_t1_comments_whole.append(comment.text)

ratings = []
comments = []

for x in h2_t1_comments_whole:
  if bool(re.search('\\[\\d+\\.0\\]', x)) == False:
    ratings.append('No Rating')
    cleaned_text = x.strip('"')
    comments.append(cleaned_text)
  else:
    rate = (re.search('\\[\\d+\\.0\\]', x))
    ratings.append(rate.group(0))

    comment_text = (re.sub(r".*?\]", "", x).strip())
    cleaned_text = comment_text.strip('"')
    comments.append(cleaned_text)

cleaned_ratings =[]

for rating in ratings:
  if rating == 'No Rating':
    rating = None
    cleaned_ratings.append(rating)
  else:
    rating = re.sub("(\[|\])", "", rating)
    rating = float(rating)
    cleaned_ratings.append(rating)

```

## Task 2

Perform any form of sentiment analysis. What is the relationship between a reviewer's sentiment and their rating?
```{python}
from bs4 import BeautifulSoup
import pandas as pd
import requests
import transformers
from transformers import pipeline
import torch
import re
```

```{python}
# The HuggingFace folks are just making stuff too easy at this point: 
# https://huggingface.co/docs/transformers/main_classes/pipelines

sentiment_analysis = pipeline('sentiment-analysis')

sentences_per_comment = []

sentences_per_comment = []

for text_block in comments:
    truncated_comment = text_block[:500]  # Take only the first 500 characters
    sentence_list = re.split(r'\.\s*', truncated_comment)  # Split by period followed by any whitespace
    sentence_list = [sentence.strip() for sentence in sentence_list]  # Trim whitespace from each sentence
    sentences_per_comment.append(sentence_list)

print(sentences_per_comment)

all_comments_number = len(sentences_per_comment)
sentiment_scores = []
sentiment_labels = []

for com_num in range(0, all_comments_number):
  comment_score = 0
  label_score = []
  for sentence in sentences_per_comment[com_num]:
    result = sentiment_analysis(sentence)
    comment_score += result[0]['score']
    label_score.append(result[0]['label'])
  sentiment_labels.append(label_score)
  sentiment_scores.append(comment_score)

mostly_sentiment = []

for label in sentiment_labels:
  if label.count('POSITIVE') > label.count('NEGATIVE'):
    mostly_sentiment.append('POSITIVE')
  elif label.count('POSITIVE') < label.count('NEGATIVE'):
    mostly_sentiment.append('NEGATIVE')
  else:
    mostly_sentiment.append('NEUTRAL')
```

```{python}
complete_df = pd.DataFrame(
    {'comments': comments,
      'leaning_sentiment': mostly_sentiment,
     'ratings': cleaned_ratings,
     'sentiment_scores': sentiment_scores,
     'sentiment_labels': sentiment_labels
    })

print(complete_df)
```

Generally speaking, a 10 rating indicates a positive tone and sentimental analysis. There are fluctuations in the sentimental score themselves (ranging from 1-5 in the 10 range), but generally speaking, it indicates a stronger sentiment towards positive with some negative sentiment ratings around. The flip side can also be observed. Lower ratings generally display a negative sentiment, but there are some positive sentiments in the mix.

## Task 3

Perform any type of topic modeling on the comments. What are the main topics of the comments? How can you use those topics to understand what people value?

```{python}
# bertopic is for transformers
from bertopic import BERTopic
from bertopic.vectorizers import ClassTfidfTransformer
# joblib is for saving and loading objects
from joblib import load, dump
```

```{python}
ctfidf_model = ClassTfidfTransformer(
  reduce_frequent_words=True
)
```

Notice that we can't use pandas objects directly, but have to convert them to lists.

```{python}
import os

save_path = '/Users/John/Documents/Visual Studio Python/uda_notes/'

# Ensure the directory exists
os.makedirs(save_path, exist_ok=True)

save_path = os.path.join(save_path, "h2_topic_model.joblib")

topic_model = BERTopic(ctfidf_model=ctfidf_model)
```

```{python}

topics, probs = topic_model.fit_transform(comments)
```

```{python}
dump(
  [topic_model, topics, probs], 
  '/Users/John/Documents/Visual Studio Python/uda_notes/h2_topic_model.joblib'
)
```

```{python}
topic_model, topics, probs = load(
  '/Users/John/Documents/Visual Studio Python/uda_notes/h2_topic_model.joblib'
)
topic_model.get_topic_info()

topic_model.get_topic(0)

topic_model.get_document_info(comments)

topic_model.get_representative_docs(0)

topic_model.generate_topic_labels()

topic_model.reduce_topics(comments, nr_topics=20)
```

Some of the topics include:
- German comments = zero correlation whatsoever. The model cannot find anything between comments if it cannot understand the language.
- Many of the comments are attributed to the wrestler's performance and legacy on the game. "Eletrifying, legendary, best ever" are some of the topics that are covered.
- Other topics also center around particular wrestlers and their names (given the amount of frequency they pop up in matchups).
- Some niche topics include funny/comedic ones that poke fun at wrestlers or complain about the referees. 

All in all, the topics generally center around the game (as it would in any other sport). The main senitment though that we can take away from the topic model exploration is understanding that fans of the WWE love the electrifying atmosphere that it brings. Stars, bright moments, flashy stunts, that is what wrestling is all about.